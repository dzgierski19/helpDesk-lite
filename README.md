ğŸ“Œ Helpdesk Lite â€” Prompt-Driven Development (PDD)

Helpdesk Lite is a complete, two-tier system (Laravel + Angular) with triage, API integration, and a UI Storybook â€” built using a Prompt-Driven Development (PDD) approach with:

- **Gemini CLI** â†’ generating prompts and commands
- **Codex (gpt-5.1-codex)** â†’ generating code
- **project_spec.md** â†’ single source of truth
- **notes/llm/** â†’ LLM iteration logs

The repository contains a complete backend, frontend, Storybook, and a full LLM workflow.

---

### ğŸ— Project Structure (monorepo)
```
helpdesk-lite/
â”‚
â”œâ”€â”€ project_spec.md           # full product specification (source of truth)
â”œâ”€â”€ README.md                 # instructions + workflow
â”œâ”€â”€ .gemini/                  # commands for Gemini CLI
â”œâ”€â”€ notes/llm/                # logs of prompts and model responses
â”‚
â”œâ”€â”€ backend/                  # Laravel 10 (API)
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ ...
â”‚
â””â”€â”€ frontend/                 # Angular + Storybook
    â”œâ”€â”€ src/
    â”œâ”€â”€ .storybook/
    â”œâ”€â”€ ...
```

---

### ğŸ§  Prompt-Driven Development (PDD)

In this project, code is not written manually.
Each major step:

1.  starts as a prompt for Gemini,
2.  Gemini generates a command â†’ goes into `.gemini/commands.yaml`,
3.  `codex run` generates code,
4.  the result is saved in `notes/llm/`.

The entire process is transparent and reproducible.

To keep both CLIs in sync we mirror the slash commands into `.codex/codex.toml`.  
After editing `.gemini/commands.yaml`, run:

```
npm run sync:commands
```

This script regenerates the Codex config so `codex run <command>` and Gemini slash commands stay identical.

For a one-off run directly from the terminal (without the interactive Codex prompt), use:

```
npm run codex -- backend:make-migrations
```

That command reads the prompt from `.gemini/commands.yaml`, forwards it to `codex exec`, and automatically stores the full Markdown log in `notes/llm/`.

---

### ğŸ§° How to run the project
**Backend (Laravel)**
```bash
cd backend
composer install
php artisan migrate --seed
php artisan serve
```

Or in a Dockerized version (if using Docker Compose):
```bash
docker compose up --build
```

**Frontend (Angular)**
```bash
cd frontend
npm install
npm start
```

**Storybook**
```bash
cd frontend
npm run storybook
```

---

### ğŸ” Roles and login

Login is "fake" â€” role selection from a dropdown:

- `admin`
- `agent`
- `reporter`

The role goes into:
- `localStorage.userRole`

The Angular Interceptor adds:
- `X-USER-ROLE: <role>`

Missing role â†’ redirect to `/login`.

---

### ğŸ—„ Git workflow (professional, used in the project)

The project uses a simple, clear workflow:

**Branches**

- `main` â†’ stable, final version of the task
- `dev` â†’ current work
- `feat/*` â†’ feature branches

**Accepted commit types**

- `chore`: configs, structure
- `feat`: functionality
- `fix`: bug fixes
- `docs`: documentation
- `refactor`: refactoring

**Examples:**
```
chore: initial project structure (backend + frontend)
feat(backend): add Ticket model and migrations
feat(frontend): implement login flow
docs: describe LLM Flow in README
```

---

### ğŸ“š Definition of Done (DoD) â€“ according to specification
**Backend**

- âœ” CRUD tickets
- âœ” filtering
- âœ” roles (reporter sees only their own)
- âœ” triage mock
- âœ” API integration + cache
- âœ” seeds

**Frontend**

- âœ” login & role
- âœ” redirect on missing role
- âœ” interceptor
- âœ” list
- âœ” details + triage + userInfo

**Storybook**

- âœ” PriorityBadge â€“ 3 stories
- âœ” TicketCard â€“ 3 stories

**LLM Flow**

- âœ” `.gemini/commands.yaml`
- âœ” full logs in `notes/llm/`
- âœ” README describes the process

---

### ğŸ§© LLMs used in the project

- **Google Gemini CLI** â€“ generating prompts, reflection, iteration
- **OpenAI Codex (gpt-5.1-codex)** â€“ generating backend, frontend, and Storybook code
- **project_spec.md** â€“ single source of truth, included in all commands

---

### âœ” Summary

The repository contains:

- complete backend + frontend + Storybook,
- full PDD process used in practice,
- clear Git workflow,
- complete project specification,
- full LLM logs (proof of work).
